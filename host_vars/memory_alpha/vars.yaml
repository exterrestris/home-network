---
ansible_host: 192.168.5.132
target_os: ubuntu

scans_user:
  username: scans
  password: "{{ vault_scans_user_password | password_hash('sha512', 65534 | random(seed=inventory_hostname) | string) }}"
  group: scans

scans_user_samba:
  name: Scans
  password: "{{ vault_scans_user_password }}"

appdata_path: /mnt/zfs/appdata

nas_additional_users:
  - "{{ scans_user }}"

nas_additional_groups:
  - name: "{{ scans_user.group }}"

media_downloads_mountpoint: "/mnt/zfs/media-downloads"

### mrlesmithjr.zfs
zfs_pools:
  - name: ssd1
    action: 'create'
    import: force
    compression: 'lz4'
    devices:
      # WD_Red_SN700_1000GB_23171U800295
      - 'nvme-WD_Red_SN700_1000GB_23171U800295'
      # WD_Red_SN700_1000GB_23171U800244
      - 'nvme-WD_Red_SN700_1000GB_23171U800244'
    type: 'mirror'
    properties:
      ashift: 12
      autoexpand: 'on'
    state: present
  - name: storage1
    action: create
    import: force
    compression: 'lz4'
    devices:
      # ST12000NM007G ZTN0KBAZ (12TB)
      - 'wwn-0x5000c500dccb5155'
      # WD120EMAZ 8CKANMKF (12TB)
      - 'wwn-0x5000cca26fef1fab'
      # WD120EMAZ 8CKATPYE (12TB)
      - 'wwn-0x5000cca26fef2ef9'
      # WD120EMAZ 8CJX3YAF (12TB)
      - 'wwn-0x5000cca26fe8f836'
      # WD120EMAZ 8CJY60HE (12TB)
      - 'wwn-0x5000cca26fe9745a'
      # ST12000NM001G WTN04568 (12TB)
      - 'wwn-0x5000c500e0b84a62'
      # ST12000NM001G WTN02E3D (12TB)
      - 'wwn-0x5000c500e03309cf'
      # ST16000NM001G ZL2PV9FM (16TB)
      - 'wwn-0x5000c500e54d7b9b'
      # WD121PURP D7J5A86N (12TB)
      - 'wwn-0x5000cca2dfde9b65'
    type: 'raidz2'
    properties:
      ashift: 12
      autoexpand: 'on'
    recordsize: 1M
    state: present
  - name: storage1
    action: add
    compression: 'lz4'
    type: 'special mirror'
    devices:
      # INTEL SSDSC2KB24 BTYF93620B8Y240AGN (240GB)
      - 'wwn-0x55cd2e415163f97a'
      # INTEL SSDSC2BB16 PHWL510301JX160MGN (160GB) (temp)
      - 'wwn-0x55cd2e404c4f1b91'
      # SAMSUNG MZ7KM480 S3F4NX0K702570 (480GB) (temp)
      - 'wwn-0x5002538c40b0f69a'
    state: present
  - name: ssd2
    action: 'create'
    import: force
    compression: 'lz4'
    devices:
      # Micron 5400 Pro 240746EFB42B (1.92TB)
      - 'wwn-0x500a075146efb42b'
      # Micron 5400 Pro 240746EFB47C (1.92TB)
      - 'wwn-0x500a075146efb47c'
    type: 'mirror'
    properties:
      ashift: 12
      autoexpand: 'on'
    state: present
  - name: ssd2
    action: 'add'
    compression: 'lz4'
    devices:
      # Micron 5400 Pro 240646CF5ABE (1.92TB)
      - 'wwn-0x500a075146cf5abe'
      # Micron 5400 Pro 240646CF197D (1.92TB)
      - 'wwn-0x500a075146cf197d'
    type: 'mirror'
    state: present
    properties:
      ashift: 12

zfs_filesystems:
  - name: backups
    pool: storage1
    compression: lz4
    mountpoint: /mnt/zfs/backups
    owner: "{{ main_user.username }}"
    group: backups
    mode: 2775
    state: present
  - name: backups/computers
    pool: storage1
    compression: lz4
    recordsize: 1M
    state: present
    owner: "{{ main_user.username }}"
    group: backups
    mode: 2775
  - name: backups/computers/uss-enterprise
    pool: storage1
    compression: lz4
    recordsize: 1M
    state: present
    owner: "{{ main_user.username }}"
    group: backups
    mode: 2775
  - name: backups/computers/uss-bellerophon
    pool: storage1
    compression: lz4
    recordsize: 1M
    state: present
    owner: "{{ main_user.username }}"
    group: backups
    mode: 2775
  - name: backups/computers/uss-prometheus
    pool: storage1
    compression: lz4
    recordsize: 1M
    state: present
    owner: "{{ main_user.username }}"
    group: backups
    mode: 2775
  - name: backups/computers/uss-rio-grande
    pool: storage1
    compression: lz4
    recordsize: 1M
    state: present
    owner: "{{ main_user.username }}"
    group: backups
    mode: 2775
  - name: backups/computers/jupiter-station
    pool: storage1
    compression: lz4
    recordsize: 1M
    state: present
    owner: "{{ main_user.username }}"
    group: backups
    mode: 2775
  - name: backups/drives
    pool: storage1
    compression: lz4
    recordsize: 1M
    state: present
  - name: archive
    pool: storage1
    compression: lz4
    mountpoint: /mnt/zfs/archive
    owner: "{{ main_user.username }}"
    group: archive
    mode: 2775
    state: present
  - name: resources
    pool: storage1
    compression: lz4
    mountpoint: /mnt/zfs/resources
    owner: "{{ main_user.username }}"
    group: resources
    mode: 2775
    state: present
  - name: photos
    pool: storage1
    compression: lz4
    mountpoint: "/mnt/zfs/photos"
    owner: "{{ main_user.username }}"
    group: photos
    mode: 2775
    state: present
  - name: appdata
    pool: ssd1
    compression: lz4
    mountpoint: "{{ appdata_path }}"
    state: present
  - name: media
    pool: storage1
    compression: lz4
    mountpoint: /mnt/media
    owner: "{{ main_user.username }}"
    group: media
    mode: 2775
    state: present
  - name: media/movies
    pool: storage1
    compression: lz4
    state: present
    owner: "{{ main_user.username }}"
    group: media
    mode: 2775
  - name: media/movies/rips
    pool: storage1
    compression: lz4
    recordsize: 1M
    state: present
    owner: "{{ main_user.username }}"
    group: media
    mode: 2775
  - name: media/shows
    pool: storage1
    compression: lz4
    state: present
    owner: "{{ main_user.username }}"
    group: media
    mode: 2775
  - name: media/shows/rips
    pool: storage1
    compression: lz4
    recordsize: 1M
    state: present
    owner: "{{ main_user.username }}"
    group: media
    mode: 2775
  - name: media/shows/recordings
    pool: storage1
    compression: lz4
    state: present
    owner: "{{ main_user.username }}"
    group: media
    mode: 2775
  - name: media/music
    pool: storage1
    compression: lz4
    state: present
    owner: "{{ main_user.username }}"
    group: media
    mode: 2775
  - name: media/reactions
    pool: storage1
    compression: lz4
    recordsize: 1M
    state: present
    owner: "{{ main_user.username }}"
    group: media
    mode: 2775
  - name: media/videos
    pool: storage1
    compression: lz4
    recordsize: 1M
    state: present
    owner: "{{ main_user.username }}"
    group: media
    mode: 2775
  - name: downloads
    pool: storage1
    compression: lz4
    recordsize: 1M
    mountpoint: /mnt/downloads
    owner: "{{ main_user.username }}"
    group: downloads
    mode: 2775
    state: present
  - name: downloads/media
    pool: storage1
    compression: lz4
    recordsize: 1M
    mountpoint: "{{ media_downloads_mountpoint }}"
    owner: "{{ main_user.username }}"
    group: downloads
    mode: 2775
    state: present
  - name: transient
    pool: ssd2
    compression: lz4
    mountpoint: /mnt/transient
    state: present


### exterrestris.sanoid
sanoid_datasets:
  - name: storage1/archive
    templates: enhanced
  - name: storage1/backups
    templates: standard
  - name: storage1/backups/computers
    templates: standard
    recursive: yes
  - name: storage1/backups/drives
    templates: standard
  - name: storage1/resources
    templates: standard
  - name: storage1/photos
    templates: enhanced
  - name: storage1/media
    templates: minimal
  - name: storage1/media/music
    templates: enhanced
  - name: storage1/media/reactions
    templates: standard
  - name: storage1/media/movies
    templates: minimal
    recursive: yes
  - name: storage1/media/shows
    templates: minimal
    recursive: yes
  - name: storage1/media/videos
    templates: minimal
  - name: storage1/downloads
    templates: basic
  - name: storage1/downloads/media
    templates: minimal
  - name: ssd1/appdata
    templates: docker
  - name: ssd2/transient
    templates: interim

syncoid_syncs:
  - name: backup-archive
    src: storage1/archive
    dest: backup1/memory-alpha/archive
    dest_host: "memory-beta.{{ internal_domain }}"
    healthchecks:
      slug: memory-alpha-backup-archive
  - name: backup-backups
    src: storage1/backups
    recursive: yes
    dest: backup1/memory-alpha/backups
    dest_host: "memory-beta.{{ internal_domain }}"
    healthchecks:
      slug: memory-alpha-backup-backups
  - name: backup-media
    src: storage1/media
    dest: backup1/memory-alpha/media
    dest_host: "memory-beta.{{ internal_domain }}"
    healthchecks:
      slug: memory-alpha-backup-media
  - name: backup-music
    src: storage1/media/music
    dest: backup1/memory-alpha/media/music
    dest_host: "memory-beta.{{ internal_domain }}"
    healthchecks:
      slug: memory-alpha-backup-music
  - name: backup-reactions
    src: storage1/media/reactions
    dest: backup1/memory-alpha/media/reactions
    dest_host: "memory-beta.{{ internal_domain }}"
    healthchecks:
      slug: memory-alpha-backup-reactions
  - name: backup-photos
    src: storage1/photos
    dest: backup1/memory-alpha/photos
    dest_host: "memory-beta.{{ internal_domain }}"
    healthchecks:
      slug: memory-alpha-backup-photos
  - name: backup-resources
    src: storage1/resources
    dest: backup1/memory-alpha/resources
    dest_host: "memory-beta.{{ internal_domain }}"
    healthchecks:
      slug: memory-alpha-backup-resources
  - name: backup-appdata
    src: ssd1/appdata
    dest: backup1/memory-alpha/appdata
    dest_host: "memory-beta.{{ internal_domain }}"
    send_options: ''
    healthchecks:
      slug: memory-alpha-backup-appdata

### mount_disks
parity_disks: []

data_disks: []

other_disks: []

ntfs_data_disks:

other_mounts:
  - path: /mnt/zfs

remove_mounts:

### tigattack.mergerfs
mergerfs_mounts:
  - path: /mnt/media/shows/downloads
    branches:
      - "{{ media_downloads_mountpoint }}/media/shows/Download*"
    options: "{{ mergerfs_opts }},category.create={{ mergerfs_policy }},x-systemd.requires=zfs-mount.service"
  - path: /mnt/media/movies/downloads
    branches:
      - "{{ media_downloads_mountpoint }}/media/movies/Download*"
    options: "{{ mergerfs_opts }},category.create={{ mergerfs_policy }},x-systemd.requires=zfs-mount.service"
  - path: /mnt/downloads/torrents
    branches:
      - "{{ media_downloads_mountpoint }}/torrents"
    options: "{{ mergerfs_opts }},category.create={{ mergerfs_policy }},x-systemd.requires=zfs-mount.service"

### vladgh.samba.server
samba_users:
  - "{{ main_user_samba }}"
  - "{{ scans_user_samba }}"

samba_map_to_guest: 'bad user'

samba_shares:
  - name: Archive
    path: /mnt/zfs/archive
    owner: "{{ main_user.username }}"
    group: archive
    directory_mode: '2775'
    writable: yes
    guest_ok: no
  - name: Backups
    path: /mnt/zfs/backups
    owner: "{{ main_user.username }}"
    group: backups
    directory_mode: '2775'
    writable: yes
    guest_ok: no
  - name: Photos
    path: /mnt/zfs/photos
    owner: "{{ main_user.username }}"
    group: photos
    directory_mode: '2775'
    writable: yes
    guest_ok: yes
  - name: Media
    path: /mnt/media
    owner: "{{ main_user.username }}"
    group: media
    directory_mode: '2775'
    writable: yes
    guest_ok: yes
  - name: Jellyfin DVR
    path: /mnt/transient/dvr
    owner: "jellyfin"
    group: media
    directory_mode: '2775'
    writable: no
    guest_ok: yes
  - name: Resources
    path: /mnt/zfs/resources
    owner: "{{ main_user.username }}"
    group: resources
    create_mode: '775'
    directory_mode: '2775'
    writable: yes
    public: yes
    guest_ok: yes
  - name: Downloads
    path: /mnt/downloads
    owner: "{{ main_user.username }}"
    group: downloads
    create_mode: '775'
    directory_mode: '2775'
    writable: yes
    public: yes
    guest_ok: yes
  - name: Scans
    path: /mnt/transient/Scans
    owner: "{{ scans_user.username }}"
    group: "{{ scans_user.group }}"
    directory_mode: '2775'
    writable: yes
    guest_ok: yes

### exterrestris.traefik
traefik_services:
  - name: jellyfin-svc
    type: http
    servers:
      - "http://jellyfin.{{ internal_domain }}:8096"

### weareinteractive.ufw
docker_ufw_rules:
  # Traefik proxy
  - rule: allow
    to_port: 8096
    proto: tcp
    interface_in: "{{ traefik_docker_network_bridge_name }}"
  # DLNA
  - rule: allow
    to_port: 1900
    proto: udp
  - rule: allow
    proto: igmp
  # Jellyfin Server Discovery
  - rule: allow
    to_port: 7359
    proto: udp
  # HDHomeRun
  - rule: allow
    from_ip: 192.168.5.162
    proto: udp

### exterrestris.docker_compose
docker_compose_projects:
  - project_dir: "{{ appdata_path }}/media"
    containers:
      - service_name: jellyfin
        image:
          name: linuxserver/jellyfin
          tag: latest
        environment:
          - PUID={{ (container_users | selectattr('username', 'equalto', 'jellyfin') | list | first).uid }}
          - PGID={{ (nas_common_groups | selectattr('name', 'equalto', 'media') | list | first).gid }}
          - TZ=Europe/London
        volumes:
          - source: "{{ appdata_path }}/media/jellyfin"
            target: /config
            group: "jellyfin"
            owner: "jellyfin"
            mode: "755"
          - source: /mnt/media/shows
            target: /media/shows
            group: media
            mode: "g+rx"
          - source: /mnt/media/movies
            target: /media/movies
            group: media
            mode: "g+rx"
          - source: /mnt/media/music
            target: /media/music
            group: media
            mode: "g+rx"
          - source: /mnt/media/reactions
            target: /media/reactions
            group: media
            mode: "g+rx"
          - source: /mnt/transient/dvr
            target: /media/dvr
            group: media
            mode: "g+rwxs"
          - source: /mnt/transient/transcodes
            target: /config/data/transcodes
            owner: jellyfin
            group: jellyfin
            mode: "u+rwx"
        network_mode: "host"
        restart: unless-stopped
        labels:
          - "traefik.enable=true"
          ## Router
          - "traefik.http.routers.jellyfin.entryPoints=https"
          - "traefik.http.routers.jellyfin.rule=Host(`jellyfin.{{ internal_domain }}`)" # OPTIONAL: && PathPrefix(`/jellyfin`)
          - "traefik.http.routers.jellyfin.tls=true"
          - "traefik.http.routers.jellyfin.middlewares=jellyfin-mw"
          - "traefik.http.routers.jellyfin.service=jellyfin-svc@file"
          ## Middleware
          - "traefik.http.middlewares.jellyfin-mw.headers.customResponseHeaders.X-Robots-Tag=noindex,nofollow,nosnippet,noarchive,notranslate,noimageindex"
          - "traefik.http.middlewares.jellyfin-mw.headers.frameDeny=true"
          - "traefik.http.middlewares.jellyfin-mw.headers.contentTypeNosniff=true"
          - "traefik.http.middlewares.jellyfin-mw.headers.browserXSSFilter=true"
          - "traefik.http.middlewares.jellyfin-mw.headers.customFrameOptionsValue='allow-from https://jellyfin.{{ internal_domain }}'"
          ## Service
          - "traefik.http.services.jellyfin-svc.loadBalancer.server.port=8096"
          - "traefik.http.services.jellyfin-svc.loadbalancer.server.scheme=http"
          - "traefik.http.services.jellyfin-svc.loadBalancer.passHostHeader=true"
    networks:
      - name: media
        external: true
        alias: "{{ traefik_docker_network }}"
  - project_dir: "{{ appdata_path }}/torrents"
    containers:
      - service_name: vpn
        image: qmcgaw/gluetun
        container_name: gluetun
        cap_add:
          - NET_ADMIN
        networks:
          - proxy
        expose:
          # qBittorrent WebUI
          - 8080
        volumes:
          - gluetun:/gluetun
        devices:
          - "/dev/net/tun:/dev/net/tun"
        environment:
          - VPN_SERVICE_PROVIDER=airvpn
          - VPN_TYPE=wireguard
          - WIREGUARD_PRIVATE_KEY={{ vault_airvpn_wireguard_private_key }}
          - WIREGUARD_PRESHARED_KEY={{ vault_airvpn_wireguard_preshared_key }}
          - WIREGUARD_ADDRESSES=10.186.35.228/32
          - SERVER_COUNTRIES=Netherlands
          - FIREWALL_VPN_INPUT_PORTS={{ vault_airvpn_port }}
          - TZ=Europe/London
        restart: always
        labels:
          - "traefik.enable=true"
          ## Router
          - "traefik.http.routers.qbittorrent.entryPoints=https"
          - "traefik.http.routers.qbittorrent.rule=Host(`qbittorrent.{{ ansible_hostname }}.{{ internal_domain }}`)"
          - "traefik.http.routers.qbittorrent.tls=true"
          ## Service
          - "traefik.http.services.qbittorrent-svc.loadBalancer.server.port=8080"
          - "traefik.http.services.qbittorrent-svc.loadbalancer.server.scheme=http"
          - "traefik.http.services.qbittorrent-svc.loadBalancer.passHostHeader=true"
      - service_name: qbittorrent
        image:
          name: ghcr.io/linuxserver/qbittorrent
          tag: version-14.3.9.99202110311443-7435-01519b5e7ubuntu20.04.1
        container_name: qbittorrent
        environment:
          - PUID={{ (container_users | selectattr('username', 'equalto', 'torrents') | list | first).uid }}
          - PGID={{ (nas_common_groups | selectattr('name', 'equalto', 'downloads') | list | first).gid }}
          - UMASK=002
          - TZ=Europe/London
          - WEBUI_PORT=8080
        volumes:
          - source: "qbittorrent"
            target: /config
            owner: "torrents"
            group: "torrents"
            mode: "755"
          - source: "{{ media_downloads_mountpoint }}/torrents"
            target: /storage/torrents
            owner: "torrents"
            group: "downloads"
            mode: "g+rx"
        network_mode: "service:vpn"
        restart: unless-stopped
    networks:
      - name: proxy
        external: true
        alias: "{{ traefik_docker_network }}"
  - project_dir: "{{ appdata_path }}/media-downloads"
    autostart: no
    containers:
      - service_name: sonarr
        image:
          name: linuxserver/sonarr
        environment:
          - PUID={{ (container_users | selectattr('username', 'equalto', 'sonarr') | list | first).uid }}
          - PGID={{ (nas_common_groups | selectattr('name', 'equalto', 'media') | list | first).gid }}
          - UMASK=002
          - TZ=Europe/London
        volumes:
          - source: sonarr
            target: /config
            group: sonarr
            owner: sonarr
            mode: "755"
          - source: sonarr.custom.d/custom-cont-init.d
            target: /custom-cont-init.d
            group: sonarr
            owner: sonarr
          - source: "{{ media_downloads_mountpoint }}"
            target: /storage
        expose:
          - 8989
        networks:
          - proxy
        restart: unless-stopped
        labels:
          - "traefik.enable=true"
          ## Router
          - "traefik.http.routers.sonarr.entryPoints=https"
          - "traefik.http.routers.sonarr.rule=Host(`sonarr.{{ internal_domain }}`)"
          - "traefik.http.routers.sonarr.tls=true"
          ## Service
          - "traefik.http.services.sonarr-svc.loadBalancer.server.port=8989"
          - "traefik.http.services.sonarr-svc.loadbalancer.server.scheme=http"
          - "traefik.http.services.sonarr-svc.loadBalancer.passHostHeader=true"
      - service_name: radarr
        image:
          name: linuxserver/radarr
        environment:
          - PUID={{ (container_users | selectattr('username', 'equalto', 'radarr') | list | first).uid }}
          - PGID={{ (nas_common_groups | selectattr('name', 'equalto', 'media') | list | first).gid }}
          - UMASK=002
          - TZ=Europe/London
        volumes:
          - source: radarr
            target: /config
            group: radarr
            owner: radarr
            mode: "755"
          - source: radarr.custom.d/custom-cont-init.d
            target: /custom-cont-init.d
            group: radarr
            owner: radarr
          - source: "{{ media_downloads_mountpoint }}"
            target: /storage
        expose:
          - 7878
        networks:
          - proxy
        restart: unless-stopped
        labels:
          - "traefik.enable=true"
          ## Router
          - "traefik.http.routers.radarr.entryPoints=https"
          - "traefik.http.routers.radarr.rule=Host(`radarr.{{ internal_domain }}`)"
          - "traefik.http.routers.radarr.tls=true"
          ## Service
          - "traefik.http.services.radarr-svc.loadBalancer.server.port=7878"
          - "traefik.http.services.radarr-svc.loadbalancer.server.scheme=http"
          - "traefik.http.services.radarr-svc.loadBalancer.passHostHeader=true"
      - service_name: radarr-1080
        image:
          name: linuxserver/radarr
        environment:
          - PUID={{ (container_users | selectattr('username', 'equalto', 'radarr') | list | first).uid }}
          - PGID={{ (nas_common_groups | selectattr('name', 'equalto', 'media') | list | first).gid }}
          - UMASK=002
          - TZ=Europe/London
        volumes:
          - source: radarr-1080
            target: /config
            group: radarr
            owner: radarr
            mode: "755"
          - source: radarr-1080.custom.d/custom-cont-init.d
            target: /custom-cont-init.d
            group: radarr
            owner: radarr
          - source: "{{ media_downloads_mountpoint }}"
            target: /storage
        expose:
          - 7879
        networks:
          - proxy
        restart: unless-stopped
        labels:
          - "traefik.enable=true"
          ## Router
          - "traefik.http.routers.radarr-1080.entryPoints=https"
          - "traefik.http.routers.radarr-1080.rule=Host(`radarr.{{ ansible_hostname }}.{{ internal_domain }}`)"
          - "traefik.http.routers.radarr-1080.tls=true"
          ## Service
          - "traefik.http.services.radarr-1080-svc.loadBalancer.server.port=7879"
          - "traefik.http.services.radarr-1080-svc.loadbalancer.server.scheme=http"
          - "traefik.http.services.radarr-1080-svc.loadBalancer.passHostHeader=true"
      - service_name: prowlarr
        image:
          name: linuxserver/prowlarr
          tag: develop
        environment:
          - PUID={{ (container_users | selectattr('username', 'equalto', 'prowlarr') | list | first).uid }}
          - PGID={{ (nas_common_groups | selectattr('name', 'equalto', 'media') | list | first).gid }}
          - UMASK=002
          - TZ=Europe/London
        volumes:
          - source: prowlarr
            target: /config
            group: prowlarr
            owner: prowlarr
            mode: "755"
        expose:
          - 9696
        networks:
          - proxy
        restart: unless-stopped
        labels:
          - "traefik.enable=true"
          ## Router
          - "traefik.http.routers.prowlarr.entryPoints=https"
          - "traefik.http.routers.prowlarr.rule=Host(`prowlarr.{{ ansible_hostname }}.{{ internal_domain }}`)"
          - "traefik.http.routers.prowlarr.tls=true"
          ## Service
          - "traefik.http.services.prowlarr-svc.loadBalancer.server.port=9696"
          - "traefik.http.services.prowlarr-svc.loadbalancer.server.scheme=http"
          - "traefik.http.services.prowlarr-svc.loadBalancer.passHostHeader=true"
      - service_name: flaresolverr
        image:
          name: flaresolverr/flaresolverr
        environment:
          - LOG_LEVEL=info
          - LOG_HTML=false
          - CAPTCHA_SOLVER=none
          - TZ=Europe/London
        expose:
          - 8191
        networks:
          - proxy
        restart: unless-stopped
        labels:
          - "traefik.enable=true"
          ## Router
          - "traefik.http.routers.flaresolverr.entryPoints=https"
          - "traefik.http.routers.flaresolverr.rule=Host(`flaresolverr.{{ ansible_hostname }}.{{ internal_domain }}`)"
          - "traefik.http.routers.flaresolverr.tls=true"
          ## Service
          - "traefik.http.services.flaresolverr-svc.loadBalancer.server.port=8191"
          - "traefik.http.services.flaresolverr-svc.loadbalancer.server.scheme=http"
          - "traefik.http.services.flaresolverr-svc.loadBalancer.passHostHeader=true"
      - service_name: ombi
        image:
          name: linuxserver/ombi
        environment:
          - PUID={{ (container_users | selectattr('username', 'equalto', 'ombi') | list | first).uid }}
          - PGID={{ (nas_common_groups | selectattr('name', 'equalto', 'media') | list | first).gid }}
          - UMASK=002
          - TZ=Europe/London
        volumes:
          - source: ombi
            target: /config
            group: ombi
            owner: ombi
            mode: "755"
        expose:
          - 3579
        networks:
          - proxy
        restart: unless-stopped
        labels:
          - "traefik.enable=true"
          ## Router
          - "traefik.http.routers.ombi.entryPoints=https"
          - "traefik.http.routers.ombi.rule=Host(`ombi.{{ internal_domain }}`)"
          - "traefik.http.routers.ombi.tls=true"
          ## Service
          - "traefik.http.services.ombi-svc.loadBalancer.server.port=3579"
          - "traefik.http.services.ombi-svc.loadbalancer.server.scheme=http"
          - "traefik.http.services.ombi-svc.loadBalancer.passHostHeader=true"
      - service_name: metube
        image:
          name: alexta69/metube
        environment:
          - YTDL_OPTIONS={"cookiefile":"/downloads/cookies.txt","writethumbnail":true,"postprocessors":[]}
          - STATE_DIR=/state
        volumes:
          - source: /mnt/downloads/metube
            target: /downloads
            owner: metube
            group: downloads
            mode: "775"
          - source: metube/state
            target: /state
            owner: metube
            group: metube
            mode: "755"
          - source: metube/yt-dlp
            target: /etc/yt-dlp
            owner: metube
            group: metube
            mode: "755"
        user: "{{ (container_users | selectattr('username', 'equalto', 'metube') | list | first).uid }}:{{ (nas_common_groups | selectattr('name', 'equalto', 'downloads') | list | first).gid }}"
        expose:
          - 8081
        networks:
          - proxy
        restart: unless-stopped
        labels:
          - "traefik.enable=true"
          ## Router
          - "traefik.http.routers.metube.entryPoints=https"
          - "traefik.http.routers.metube.rule=Host(`metube.{{ ansible_hostname }}.{{ internal_domain }}`)"
          - "traefik.http.routers.metube.tls=true"
          ## Service
          - "traefik.http.services.metube-svc.loadBalancer.server.port=8081"
          - "traefik.http.services.metube-svc.loadbalancer.server.scheme=http"
          - "traefik.http.services.metube-svc.loadBalancer.passHostHeader=true"  
    networks:
      - name: proxy
        external: true
        alias: "{{ traefik_docker_network }}"

### linuxserver_containers
linuxserver_container_custom_scripts:
  - container: "{{ appdata_path }}/media-downloads/sonarr"
    scripts:
      - script: add-to-downloads-group.sh
        template: add-container-user-to-group.sh.j2
        template_vars:
          gid: "{{ (nas_common_groups | selectattr('name', 'equalto', 'downloads') | list | first).gid }}"
          group: downloads
  - container: "{{ appdata_path }}/media-downloads/radarr"
    scripts:
      - script: add-to-downloads-group.sh
        template: add-container-user-to-group.sh.j2
        template_vars:
          gid: "{{ (nas_common_groups | selectattr('name', 'equalto', 'downloads') | list | first).gid }}"
          group: downloads
  - container: "{{ appdata_path }}/media-downloads/radarr-1080"
    scripts:
      - script: add-to-downloads-group.sh
        template: add-container-user-to-group.sh.j2
        template_vars:
          gid: "{{ (nas_common_groups | selectattr('name', 'equalto', 'downloads') | list | first).gid }}"
          group: downloads
