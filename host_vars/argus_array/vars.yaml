---
ansible_host: 192.168.5.149
target_os: ubuntu

appdata_dataset:
  name: appdata
  pool: data1
  compression: lz4
  mountpoint: /mnt/appdata
  state: present

appdata_path: "{{ appdata_dataset.mountpoint }}"

### mrlesmithjr.zfs
zfs_pools:
  - name: data1
    action: 'create'
    import: force
    compression: 'lz4'
    devices:
      # WD_Red_SN700_1000GB_24112Y801074
      - 'nvme-WD_Red_SN700_1000GB_24112Y801074'
      # WD_Red_SN700_1000GB_24112Y801475
      - 'nvme-WD_Red_SN700_1000GB_24112Y801475'
    type: 'mirror'
    properties:
      ashift: 12
      autoexpand: 'on'
    state: 'present'

zfs_datasets:
  - "{{ appdata_dataset }}"

zfs_filesystems: "{{ zfs_datasets + docker_datasets }}"

### exterrestris.sanoid
sanoid_datasets:
  - name: data1/appdata
    templates: docker
    recursive: yes

syncoid_syncs:
  - name: backup-appdata
    src: data1/appdata
    dest: backup1/argus-array/appdata
    dest_host: "memory-beta.{{ internal_domain }}"
    send_options: ''
    healthchecks:
      slug: argus-array-backup-appdata

### exterrestris.docker_compose
docker_compose_projects:
  - project_label: uptime-kuma
    project_dir: "{{ appdata_dataset.mountpoint }}/uptime-kuma"
    containers:
      - service_name: uptime-kuma
        container_name: uptime-kuma
        image:
          name: louislam/uptime-kuma
          tag: 2
        environment:
          - PUID={{ (container_users | selectattr('username', 'equalto', 'uptime-kuma') | list | first).uid }}
          - PGID={{ (container_users | selectattr('username', 'equalto', 'uptime-kuma') | list | first).gid }}
        volumes:
          - source: uptime-kuma
            target: /app/data
            group: uptime-kuma
            owner: uptime-kuma
            mode: "755"
        expose:
          - 3001
        networks:
          - proxy
        restart: always
        labels:
          - "traefik.enable=true"
          ## Router
          - "traefik.http.routers.uptime-kuma.entryPoints=https"
          - "traefik.http.routers.uptime-kuma.rule=Host(`uptime.{{ internal_domain }}`,`status.{{ internal_domain }}`)"
          - "traefik.http.routers.uptime-kuma.tls=true"
          ## Service
          - "traefik.http.services.uptime-kuma-svc.loadBalancer.server.port=3001"
          - "traefik.http.services.uptime-kuma-svc.loadbalancer.server.scheme=http"
          - "traefik.http.services.uptime-kuma-svc.loadBalancer.passHostHeader=true"
    networks:
      - name: proxy
        external: true
        alias: "{{ traefik_docker_network }}"
  - project_label: healthchecks
    project_dir: "{{ appdata_dataset.mountpoint }}/healthchecks"
    containers:
      - service_name: healthchecks
        container_name: healthchecks
        image:
          name: linuxserver/healthchecks
        environment:
          - PUID={{ (container_users | selectattr('username', 'equalto', 'healthchecks') | list | first).uid }}
          - PGID={{ (container_users | selectattr('username', 'equalto', 'healthchecks') | list | first).gid }}
          - TZ=Etc/UTC
          - SITE_ROOT=https://healthchecks.{{ internal_domain }}
          - SITE_NAME=Healthchecks
          - SUPERUSER_EMAIL=sean@terrestris.co.uk
          - SUPERUSER_PASSWORD={{ vault_healthchecks_superuser_password }}
          # - ALLOWED_HOSTS=
          - APPRISE_ENABLED=True # Must be capitalised
          # - CSRF_TRUSTED_ORIGINS=
          - DEBUG=False # Must be capitalised
          - DEFAULT_FROM_EMAIL=healthchecks@{{ internal_domain }}
          - EMAIL_HOST={{ migadu_smtp_server }}
          - EMAIL_PORT={{ migadu_smtp_tls_port }}
          - EMAIL_HOST_USER=healthchecks@{{ internal_domain }}
          - EMAIL_HOST_PASSWORD={{ vault_healthchecks_migadu_user_password }}
          - EMAIL_USE_TLS=True # Must be capitalised
          - INTEGRATIONS_ALLOW_PRIVATE_IPS=True # Must be capitalised
          # - PING_EMAIL_DOMAIN=
          # - RP_ID=
          # - SECRET_KEY=
          # - SITE_LOGO_URL=
        volumes:
          - source: healthchecks
            target: /config
            group: healthchecks
            owner: healthchecks
            mode: "755"
        expose:
          - 8000
        networks:
          - proxy
        restart: unless-stopped
        labels:
          - "traefik.enable=true"
          ## Router
          - "traefik.http.routers.healthchecks.entryPoints=https"
          - "traefik.http.routers.healthchecks.rule=Host(`healthchecks.{{ internal_domain }}`)"
          - "traefik.http.routers.healthchecks.tls=true"
          ## Service
          - "traefik.http.services.healthchecks-svc.loadBalancer.server.port=8000"
          - "traefik.http.services.healthchecks-svc.loadbalancer.server.scheme=http"
          - "traefik.http.services.healthchecks-svc.loadBalancer.passHostHeader=true"
    networks:
      - name: proxy
        external: true
        alias: "{{ traefik_docker_network }}"
  - project_label: omada-controller
    project_dir: "{{ appdata_dataset.mountpoint }}/omada-controller"
    containers:
      - service_name: omada-controller
        container_name: omada-controller
        image:
          name: mbentley/omada-controller
        ports:
          - port: 8088
          - port: 8043
          - port: 8843
          - port: 27001
            protocol: udp
          - port: 29810
            protocol: udp
          - port: 29811
          - port: 29812
          - port: 29813
          - port: 29814
        environment:
          - PUID={{ (container_users | selectattr('username', 'equalto', 'omada') | list | first).uid }}
          - PGID={{ (container_users | selectattr('username', 'equalto', 'omada') | list | first).gid }}
          - MANAGE_HTTP_PORT=8088
          - MANAGE_HTTPS_PORT=8043
          - PORTAL_HTTP_PORT=8088
          - PORTAL_HTTPS_PORT=8843
          - PORT_APP_DISCOVERY=27001
          - PORT_ADOPT_V1=29812
          - PORT_UPGRADE_V1=29813
          - PORT_MANAGER_V1=29811
          - PORT_MANAGER_V2=29814
          - PORT_DISCOVERY=29810
          - SHOW_SERVER_LOGS=true
          - SHOW_MONGODB_LOGS=false
          #- SSL_CERT_NAME=tls.crt
          #- SSL_KEY_NAME=tls.key
          - TZ=Etc/UTC
        volumes:
          - source: omada-controller/data
            target: /opt/tplink/EAPController/data
            group: omada
            owner: omada
            mode: "755"
          - source: omada-controller/logs
            target: /opt/tplink/EAPController/logs
            group: omada
            owner: omada
            mode: "755"
        restart: always
